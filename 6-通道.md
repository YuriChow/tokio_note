现在我们已经了解了一些关于 Tokio 的并发性，让我们将其应用于客户端。将我们之前编写的服务器代码放入明确的二进制文件中：
>mkdir src/bin
>mv src/main.rs src/bin/server.rs

并创建一个包含客户端代码的新二进制文件：
>touch src/bin/client.rs

在此文件中，您将编写此页面的代码。无论何时您想要运行它，您都必须首先在单独的终端窗口中启动服务器：
>cargo run --bin server

然后才是客户端，单独地：
>cargo run --bin client

说完了，让我们码代码吧！            
假设我们想要运行两个并发的 Redis 命令。我们可以为每个命令生成一个任务。那么这两个命令将同时发生。                
首先，我们可能会尝试这样的方法：
```Rust
use mini_redis::client;

#[tokio::main]
async fn main() {
    // 建立一个到服务器的链接
    let mut client = client::connect("127.0.0.1:6379").await.unwrap();

    // 生成两个任务，一个 get key，另一个 set key
    let t1 = tokio::spawn(async {
        let res = client.get("hello").await;
    });

    let t2 = tokio::spawn(async {
        client.set("foo", "bar".into()).await;
    });

    t1.await.unwrap();
    t2.await.unwrap();
}
```
这不会编译成功，因为两个任务都需要以某种方式访问 `client`。由于 `Client` 没有实现 `Copy`，所以如果没有一些代码来促进这种共享，它将无法编译。此外，`Client::set` 接收 `&mut self`，这意味着调用它需要独占访问。我们可以为每个任务打开一个连接，但这并不理想。我们不能使用 `std::sync::Mutex`，因为需要在持有锁的情况下调用 `.await`。我们可以使用 `tokio::sync::Mutex`，但这只允许一个 ***in-flight(飞行中)*** 请求。如果客户端实现 [pipelining](https://redis.io/topics/pipelining)，则异步互斥锁会导致连接利用不足。           


# 消息传递
答案是使用消息传递。该模式涉及生成一个专用任务来管理 `client` 资源。任何希望发出请求的任务都会向 `client` 任务发送消息。`client` 任务代表发送方发出请求，并且响应被发送回发送方。                
使用此策略，可以建立单个连接。管理 `client` 的任务 能够获得独占访问，以便调用 `get` 和 `set`。此外，通道作为缓冲区工作。当 `client` 任务繁忙时，可能向 `client` 任务发送操作。一旦 `client` 任务可以处理新请求，它就会从通道中拉取下一个请求。这可以提高吞吐量，并扩展到支持连接池。      


# Tokio 的 通道 原语
Tokio 提供 [number of channels](https://docs.rs/tokio/1/tokio/sync/index.html)，每个通道用于不同的目的。
- [mpsc](https://docs.rs/tokio/1/tokio/sync/mpsc/index.html)：多生产者、单消费者通道。可以发送许多值。
- [oneshot](https://docs.rs/tokio/1/tokio/sync/oneshot/index.html)：单生产者，单消费者通道。可以发送单个值。
- [broadcast](https://docs.rs/tokio/1/tokio/sync/broadcast/index.html)：多生产者、多消费者。可以发送许多值。每个接收者都能看到每个值。
- [watch](https://docs.rs/tokio/1/tokio/sync/watch/index.html)：单生产者，多消费者。可以发送许多值，但不保留历史记录。接收者仅看到最近的值。

如果您需要一个多生产者多消费者通道，其中只有一个消费者看到每条消息，则可以使用 [`async-channel`](https://docs.rs/async-channel/) 箱。在异步 ***Rust*** 之外还有一些通道可供使用，如 [`std::sync::mpsc`](https://doc.rust-lang.org/stable/std/sync/mpsc/index.html) 和 [`crossbeam::channel`](https://docs.rs/crossbeam/latest/crossbeam/channel/index.html)。这些通道通过阻塞线程来等待消息，这在异步代码中是不允许的。                     
在本节中，我们将使用 [mpsc](https://docs.rs/tokio/1/tokio/sync/mpsc/index.html) 和 [oneshot](https://docs.rs/tokio/1/tokio/sync/oneshot/index.html)。其他类型的消息传递通道将在后面的部分中探讨。本节的完整代码可在 [此处](https://github.com/tokio-rs/website/blob/master/tutorial-code/channels/src/main.rs) 找到。


# 定义消息类型
在大多数情况下，当使用消息传递时，接收消息的任务会响应多个命令。在本例中，任务将响应 `GET` 和 `SET` 命令。为了对此建模，我们首先定义一个 `Command` 枚举，并为每个命令类型包含一个变体。
```Rust
use bytes::Bytes;

#[derive(Debug)]
enum Command {
    Get {
        key: String,
    },
    Set {
        key: String,
        val: Bytes,
    }
}
```


# 创建通道
再 `main` 函数中，创建一个 `mpsc` 通道：
```Rust
use tokio::sync::mpsc;

#[tokio::main]
async fn main() {
    // 创建一个新通道，其容量为最大 32.
    let (tx, mut rx) = mpsc::channel(32);

    // ... 其余内容
}
```
`mpsc` 通道用于向管理 redis 连接的任务 ***发送*** 命令。多生产者特性允许从多个任务发送消息。创建通道返回两个值，发送器和接收器。这两个句柄分别使用。它们可以被移动到不同的任务。                 
创建的信道的容量为 32。如果消息发送速度快于接收速度，则通道将存储消息。一旦有 32 条消息存储在通道中，则调用 `send(...).await`，将进入睡眠状态，直到接收方移除消息。                   
从多个任务发送是通过 ***克隆*** 发送器来完成的。例如：
```Rust
use tokio::sync::mpsc;

#[tokio::main]
async fn main() {
    let (tx, mut rx) = mpsc::channel(32);
    let tx2 = tx.clone();

    tokio::spawn(async move {
        tx.send("sending from first handle").await;
    });

    tokio::spawn(async move {
        tx2.send("sending from second handle").await;
    });

    while let Some(message) = rx.recv().await {
        println!("GOT = {}", message);
    }
}
```
两条消息都发送到单个 `Receiver` 句柄。不可能克隆 `mpsc` 通道 的接收器。                
当每个 `Sender` 都超出范围 或 被 dropped 时，将不再可能向通道发送更多消息。此时，`Receiver` 上的 `recv` 调用将返回 `None`，这意味着所有发送器都已消失，信道关闭。                    
在我们管理 Redis 连接的任务中，它知道一旦通道关闭，它可以关闭 Redis 连接，因为连接将不再被使用。          


# 生成管理器任务
接下来，生成一个处理来自通道的消息的任务。首先，建立与 Redis 的客户端连接。然后，通过 Redis 连接发出接收到的命令。
```Rust
use mini_redis::client;
// `move` 关键字是用来 **move** `rx` 的所有权进入到 task 中。
let manager = tokio::spawn(async move {
    // 建立一个到服务器的链接
    let mut client = client::connect("127.0.0.1:6379").await.unwrap();

    // 开始接收消息
    while let Some(cmd) = rx.recv().await {
        use Command::*;

        match cmd {
            Get { key } => {
                client.get(&key).await;
            }
            Set { key, val } => {
                client.set(&key, val).await;
            }
        }
    }
});
```
现在，更新这两个任务以通过通道发送命令，而不是直接在 Redis 连接上发出命令。
```Rust
// `Sender` 句柄被 moved 进任务中，由于有两个任务，我们需要第二个 `Sender`。
let tx2 = tx.clone();

// 生成两个任务，一个 get 一个 key，另一个 set 一个 key
let t1 = tokio::spawn(async move {
    let cmd = Command::Get {
        key: "hello".to_string(),
    };

    tx.send(cmd).await.unwrap();
});

let t2 = tokio::spawn(async move {
    let cmd = Command::Set {
        key: "foo".to_string(),
        val: "bar".into(),
    };

    tx2.send(cmd).await.unwrap();
});
```
在 `main` 函数的底部，我们 `.await` join 句柄，以确保在进程退出之前命令完全完成。
```Rust
t1.await.unwrap();
t2.await.unwrap();
manager.await.unwrap();
```


# 接收响应
最后一步是接收来自 manager 任务的响应。`GET` 命令需要获取值，`SET` 命令需要知道操作是否成功完成。               
为了传递响应，使用 `oneshot` 通道。`oneshot` 通道是一个单生产者、单消费者通道，为发送单一价值而优化。在我们的例子中，单个值就是响应。                 
与 `mpsc` 类似，`oneshot::channel()` 返回发送器和接收器句柄：
```Rust
use tokio::sync::oneshot;

let (tx, rx) = oneshot::channel();
```
与 `mpsc` 不同，没有指定容量，因为容量始终为 1。此外，两个句柄都不能被克隆。               
要从 manager 任务接收响应，在发送命令之前，将创建一个 `oneshot` 通道。通道的发送器一半被包含在 manager 任务的命令中。接收器半部分用于接收响应。                        
首先，更新 `Command` 以包括 `Sender`。为方便起见，类型别名用于代表 `Sender`。
```Rust
use tokio::sync::oneshot;
use bytes::Bytes;

/// 多个不同命令 在 单个通道上 multiplexed(多路复用)
#[derive(Debug)]
enum Command {
    Get {
        key: String,
        resp: Responder<Option<Bytes>>,
    },
    Set {
        key: String,
        val: Bytes,
        resp: Responder<()>,
    },
}

/// 由请求者提供，并由 manager 任务用于发送命令响应返回给请求者。
type Responder<T> = oneshot::Sender<mini_redis::Result<T>>;
```
现在，更新任务发送命令来包含 `oneshot::Sender`：
```Rust
let t1 = tokio::spawn(async move {
    let (resp_tx, resp_rx) = oneshot::channel();
    let cmd = Command::Get {
        key: "hello".to_string(),
        resp: resp_tx,
    };

    // 发送 GET 请求
    tx.send(cmd).await.unwrap();

    // 等待响应
    let res = resp_rx.await;
    println!("GOT = {:?}", res);
});

let t2 = tokio::spawn(async move {
    let (resp_tx, resp_rx) = oneshot::channel();
    let cmd = Command::Set {
        key: "foo".to_string(),
        val: "bar".into(),
        resp: resp_tx,
    };

    // 发送 SET 请求
    tx2.send(cmd).await.unwrap();

    // 等待响应
    let res = resp_rx.await;
    println!("GOT = {:?}", res);
});
```
最后，更新 manager 任务以通过 `oneshot` 通道发送响应。
```Rust
while let Some(cmd) = rx.recv().await {
    match cmd {
        Command::Get { key, resp } => {
            let res = client.get(&key).await;
            // 忽略错误
            let _ = resp.send(res);
        }
        Command::Set { key, val, resp } => {
            let res = client.set(&key, val).await;
            // 忽略错误
            let _ = resp.send(res);
        }
    }
}
```
在 `oneshot::Sender` 上调用 `send` 立即会完成，***不*** 需要 `.await`。这是因为在 `oneshot` 通道上的 `Send` 总是立即地 失败或成功，而无需任何形式的等待。                    
当接收器一半 dropped 时，在 `oneshot` 通道上发送值会返回 `Err`。这表明接收器不再对响应感兴趣。在我们的场景中，接收方取消兴趣是可接受的事件。不需要处理 `resp.send(...)` 返回的错误。                    
您可以在 [这里](https://github.com/tokio-rs/website/blob/master/tutorial-code/channels/src/main.rs) 找到整个代码。                 


# ***Backpressure(反压)*** 和 有限通道
无论何时引入并发或排队，都必须确保队列是有限的，并且系统将优雅地处理负载。无限队列最终将填满所有可用内存，并导致系统以不可预测的方式失败。                         
Tokio 关心避免隐式排队。其中很大一部分是 ***Rust*** 的异步操作是惰性的。考虑以下例子：
```Rust
loop {
    async_op();
}
```
如果异步操作急切地运行，则循环将重复排队新的 `async_op` 以待运行，而不会确保前一个操作已完成。这会导致隐式无限排队。基于回调的系统 和 基于 ***eager*** future 的系统特别容易受到这种影响。                         
但是，对于 Tokio 和 asynchronous ***Rust***，上面的代码片段根本不会导致 `async_op` 运行。这是因为 `.await` 永远不会被调用。如果代码段更新为使用 `.await`，则循环将等待操作完成，然后才重新开始下一个循环。
```Rust
loop {
    // 将不会重复，直到 `async_op` 完成
    async_op().await;
}
```
必须显式引入 并发 和 队列。方法包括：
- `tokio::spawn`
- `select!`
- `join!`
- `mpsc::channel`

执行此操作时，请注意确保并发总量是有限的。例如，在编写 TCP 接受循环时，确保开放套接字的总数是有限的。使用 `mpsc::channel` 时，选择可管理的通道容量。特定绑定值将特定于应用程序。                     
注意并选择好的限制是编写可靠的 Tokio 应用程序的重要部分。